{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPG Examples\n",
    "This document shows how to use the PyTPG API. We make use of OpenAI Gym to run examples, and we assume you already have PyTPG installed, see the readme for installation instructions for PyTPG."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "# imports to run OpenAI Gym in Jupyter\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "# how to render in Jupyter: \n",
    "# https://stackoverflow.com/questions/40195740/how-to-run-openai-gym-render-over-a-server\n",
    "# https://www.youtube.com/watch?v=O84KgRt6AJI\n",
    "def show_state(env, step=0, name='', info=''):\n",
    "    plt.figure(3)\n",
    "    plt.clf()\n",
    "    plt.imshow(env.render(mode='rgb_array'))\n",
    "    plt.title(\"%s | Step: %d %s\" % (name, step, info))\n",
    "    plt.axis('off')\n",
    "\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    \n",
    "# transforms the state into what the tpg agent can use.\n",
    "# From 3D to 1D, taking only red data (from rgb array)\n",
    "def getState(state):\n",
    "    state2 = []\n",
    "    for x in state:\n",
    "        for y in x:\n",
    "            state2.append(y[0])\n",
    "            \n",
    "    return state2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env = gym.make('Assault-v0') # make the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(7)\n"
     ]
    }
   ],
   "source": [
    "print(env.action_space) # learn size of action space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import to do training\n",
    "from tpg.tpg_trainer import TpgTrainer\n",
    "# import to run an agent (always needed)\n",
    "from tpg.tpg_agent import TpgAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generational Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import time # for tracking time\n",
    "\n",
    "tStart = time.time()\n",
    "\n",
    "# first create an instance of the TpgTrainer\n",
    "# this creates the whole population and everything\n",
    "trainer = TpgTrainer(actions=range(7))\n",
    "\n",
    "curScores = [] # hold scores in a generation\n",
    "summaryScores = [] # record score summaries for each gen (min, max, avg)\n",
    "\n",
    "# 5 generations isn't much (not even close), but some improvements\n",
    "# should be seen.\n",
    "for gen in range(5): # generation loop\n",
    "    curScores.clear() # new list per gen\n",
    "    \n",
    "    while True: # loop to go through agents\n",
    "        teamNum = trainer.remainingAgents()\n",
    "        agent = trainer.getNextAgent()\n",
    "        if agent is None:\n",
    "            break # no more agents, so proceed to next gen\n",
    "        \n",
    "        state = env.reset() # get initial state and prep environment\n",
    "        score = 0\n",
    "        for i in range(200): # run episodes that last 200 frames\n",
    "            show_state(env, i, 'Assault', 'Gen #' + str(gen) + \n",
    "                       ', Team #' + str(teamNum) +\n",
    "                       ', Score: ' + str(score)) # render env\n",
    "            \n",
    "            act = agent.act(getState(state)) # get action from agent\n",
    "            \n",
    "            # feedback from env\n",
    "            state, reward, isDone, debug = env.step(act)\n",
    "            score += reward # accumulate reward in score\n",
    "            if isDone:\n",
    "                break # end early if losing state\n",
    "                \n",
    "        agent.reward(score) # must reward agent\n",
    "        curScores.append(score) # store score\n",
    "            \n",
    "    # at end of generation, make summary of scores\n",
    "    scoreRec.append((min(curScores), max(curScores),\n",
    "                    sum(curScores)/len(curScores))) # min, max, avg\n",
    "    \n",
    "print('Time Taken (Seconds): ' + str(time.time() - tStart))\n",
    "print('Results: ' + str(scoreRec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generational Selection with Multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 9, 16, 25, 36]\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "def runAgent(agent):\n",
    "    \n",
    "\n",
    "p = Pool(5)\n",
    "print(p.map(runAgent, [1,2,3,4,5,6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import time # for tracking time\n",
    "\n",
    "tStart = time.time()\n",
    "\n",
    "# first create an instance of the TpgTrainer\n",
    "# this creates the whole population and everything\n",
    "trainer = TpgTrainer(actions=range(7))\n",
    "\n",
    "curScores = [] # hold scores in a generation\n",
    "summaryScores = [] # record score summaries for each gen (min, max, avg)\n",
    "\n",
    "# 5 generations isn't much (not even close), but some improvements\n",
    "# should be seen.\n",
    "for gen in range(5): # generation loop\n",
    "    curScores.clear() # new list per gen\n",
    "    \n",
    "    while True: # loop to go through agents\n",
    "        teamNum = trainer.remainingAgents()\n",
    "        agent = trainer.getNextAgent()\n",
    "        if agent is None:\n",
    "            break # no more agents, so proceed to next gen\n",
    "        \n",
    "        state = env.reset() # get initial state and prep environment\n",
    "        score = 0\n",
    "        for i in range(200): # run episodes that last 200 frames\n",
    "            show_state(env, i, 'Assault', 'Gen #' + str(gen) + \n",
    "                       ', Team #' + str(teamNum) +\n",
    "                       ', Score: ' + str(score)) # render env\n",
    "            \n",
    "            act = agent.act(getState(state)) # get action from agent\n",
    "            \n",
    "            # feedback from env\n",
    "            state, reward, isDone, debug = env.step(act)\n",
    "            score += reward # accumulate reward in score\n",
    "            if isDone:\n",
    "                break # end early if losing state\n",
    "                \n",
    "        agent.reward(score) # must reward agent\n",
    "        curScores.append(score) # store score\n",
    "            \n",
    "    # at end of generation, make summary of scores\n",
    "    scoreRec.append((min(curScores), max(curScores),\n",
    "                    sum(curScores)/len(curScores))) # min, max, avg\n",
    "    \n",
    "print('Time Taken (Seconds): ' str(time.time() - tStart))\n",
    "print('Results: ' + str(scoreRec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Tournament Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:oaigym]",
   "language": "python",
   "name": "conda-env-oaigym-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
