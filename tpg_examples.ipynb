{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPG Examples\n",
    "This document shows how to use the PyTPG API. We make use of OpenAI Gym to run examples, and we assume you already have PyTPG installed, see the readme for installation instructions for PyTPG."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "# how to render in Jupyter: \n",
    "# https://stackoverflow.com/questions/40195740/how-to-run-openai-gym-render-over-a-server\n",
    "# https://www.youtube.com/watch?v=O84KgRt6AJI\n",
    "def show_state(env, step=0, name='', info=''):\n",
    "    plt.figure(3)\n",
    "    plt.clf()\n",
    "    plt.imshow(env.render(mode='rgb_array'))\n",
    "    plt.title(\"%s | Step: %d %s\" % (name, step, info))\n",
    "    plt.axis('off')\n",
    "\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    \n",
    "# To transform pixel matrix to a single vector.\n",
    "def getState(inState):\n",
    "    # each row is all 1 color\n",
    "    rgbRows = np.reshape(inState,(len(inState[0])*len(inState), 3)).T\n",
    "\n",
    "    # add each with appropriate shifting\n",
    "    # get RRRRRRRR GGGGGGGG BBBBBBBB\n",
    "    return np.add(np.left_shift(rgbRows[0], 16),\n",
    "        np.add(np.left_shift(rgbRows[1], 8), rgbRows[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env = gym.make('Assault-v0') # make the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(7)\n"
     ]
    }
   ],
   "source": [
    "print(env.action_space) # learn size of action space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import to do training\n",
    "from tpg.trainer import Trainer\n",
    "# import to run an agent (always needed)\n",
    "from tpg.agent import Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Basic Generational Selection (with graphics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken (Seconds): 1360.6167724132538\n",
      "Results:\n",
      "Min, Max, Avg\n",
      "0.0 63.0 9.45\n",
      "0.0 63.0 8.4\n",
      "0.0 63.0 9.0\n",
      "0.0 63.0 12.0\n",
      "0.0 84.0 20.045454545454547\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import time # for tracking time\n",
    "\n",
    "tStart = time.time()\n",
    "\n",
    "# first create an instance of the TpgTrainer\n",
    "# this creates the whole population and everything\n",
    "trainer = Trainer(actions=range(7), teamPopSize=20, rTeamPopSize=20) # teamPopSize should realistically be at-least 100\n",
    "\n",
    "curScores = [] # hold scores in a generation\n",
    "summaryScores = [] # record score summaries for each gen (min, max, avg)\n",
    "\n",
    "# 5 generations isn't much (not even close), but some improvements\n",
    "# should be seen.\n",
    "for gen in range(5): # generation loop\n",
    "    curScores = [] # new list per gen\n",
    "    \n",
    "    agents = trainer.getAgents()\n",
    "    \n",
    "    while True: # loop to go through agents\n",
    "        teamNum = len(agents)\n",
    "        agent = agents.pop()\n",
    "        if agent is None:\n",
    "            break # no more agents, so proceed to next gen\n",
    "        \n",
    "        state = env.reset() # get initial state and prep environment\n",
    "        score = 0\n",
    "        for i in range(100): # run episodes that last 200 frames\n",
    "            show_state(env, i, 'Assault', 'Gen #' + str(gen) + \n",
    "                       ', Team #' + str(teamNum) +\n",
    "                       ', Score: ' + str(score)) # render env\n",
    "\n",
    "            # must transform to at-least int-32 (for my getState to bitshift correctly)\n",
    "            act = agent.act(getState(np.array(state, dtype=np.int32))) # get action from agent\n",
    "\n",
    "            # feedback from env\n",
    "            state, reward, isDone, debug = env.step(act)\n",
    "            score += reward # accumulate reward in score\n",
    "            if isDone:\n",
    "                break # end early if losing state\n",
    "\n",
    "        agent.reward(score) # must reward agent (if didn't already score)\n",
    "            \n",
    "        curScores.append(score) # store score\n",
    "        \n",
    "        if len(agents) == 0:\n",
    "            break\n",
    "            \n",
    "    # at end of generation, make summary of scores\n",
    "    summaryScores.append((min(curScores), max(curScores),\n",
    "                    sum(curScores)/len(curScores))) # min, max, avg\n",
    "    trainer.evolve()\n",
    "    \n",
    "#clear_output(wait=True)\n",
    "print('Time Taken (Seconds): ' + str(time.time() - tStart))\n",
    "print('Results:\\nMin, Max, Avg')\n",
    "for result in summaryScores:\n",
    "    print(result[0],result[1],result[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Generational Selection with Multiprocessing (no graphics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example is just to show a different way to run the API, a far superior way. It uses a different method to get the agents, doesn't use graphics (but can), and uses multiprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Run each agent in this method for parallization.\n",
    "Args:\n",
    "    args: (TpgAgent, envName, scoreList, numEpisodes, numFrames)\n",
    "\"\"\"\n",
    "def runAgent(args):\n",
    "    agent = args[0]\n",
    "    envName = args[1]\n",
    "    scoreList = args[2]\n",
    "    numEpisodes = args[3] # number of times to repeat game\n",
    "    numFrames = args[4] \n",
    "    \n",
    "    # skip if task already done by agent\n",
    "    if agent.taskDone(envName+'-'+str(numFrames)):\n",
    "        print('Agent #' + str(agent.agentNum) + ' can skip.')\n",
    "        scoreList.append((agent.team.id, agent.team.outcomes))\n",
    "        return\n",
    "    \n",
    "    env = gym.make(envName)\n",
    "    valActs = range(env.action_space.n) # valid actions, some envs are less\n",
    "    \n",
    "    scoreTotal = 0 # score accumulates over all episodes\n",
    "    for ep in range(numEpisodes): # episode loop\n",
    "        state = env.reset()\n",
    "        scoreEp = 0\n",
    "        numRandFrames = 0\n",
    "        if numEpisodes > 1:\n",
    "            numRandFrames = random.randint(0,30)\n",
    "        for i in range(numFrames): # frame loop\n",
    "            if i < numRandFrames:\n",
    "                _, _, isDone, _ = env.step(env.action_space.sample())\n",
    "                if isDone: # don't count it if lose on random steps\n",
    "                    ep -= 1\n",
    "                continue\n",
    "\n",
    "            act = agent.act(getState(state))\n",
    "\n",
    "            # feedback from env\n",
    "            state, reward, isDone, debug = env.step(act)\n",
    "            scoreEp += reward # accumulate reward in score\n",
    "            if isDone:\n",
    "                break # end early if losing state\n",
    "                \n",
    "        print('Agent #' + str(agent.agentNum) + \n",
    "              ' | Ep #' + str(ep) + ' | Score: ' + str(scoreEp))\n",
    "        scoreTotal += scoreEp\n",
    "       \n",
    "    scoreTotal /= numEpisodes\n",
    "    env.close()\n",
    "    agent.reward(scoreTotal, envName+'-'+str(numFrames))\n",
    "    scoreList.append((agent.team.id, agent.team.outcomes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent #0 can skip.\n",
      "Agent #7 can skip.\n",
      "Agent #1 can skip.\n",
      "Agent #2 can skip.\n",
      "Agent #3 can skip.\n",
      "Agent #4 can skip.\n",
      "Agent #5 can skip.\n",
      "Agent #6 can skip.\n",
      "Agent #8 can skip.\n",
      "Agent #9 can skip.\n",
      "Agent #15 can skip.\n",
      "Agent #10 can skip.\n",
      "Agent #11 can skip.\n",
      "Agent #16 can skip.\n",
      "Agent #12 can skip.\n",
      "Agent #30 can skip.\n",
      "Agent #17 can skip.\n",
      "Agent #13 can skip.\n",
      "Agent #14 can skip.\n",
      "Agent #18 can skip.\n",
      "Agent #19 can skip.\n",
      "Agent #31 can skip.\n",
      "Agent #20 can skip.\n",
      "Agent #21 can skip.\n",
      "Agent #32 can skip.\n",
      "Agent #22 can skip.\n",
      "Agent #33 can skip.\n",
      "Agent #23 can skip.\n",
      "Agent #24 can skip.\n",
      "Agent #25 can skip.\n",
      "Agent #45 can skip.\n",
      "Agent #26 can skip.\n",
      "Agent #27 can skip.\n",
      "Agent #46 can skip.\n",
      "Agent #28 can skip.\n",
      "Agent #34 can skip.\n",
      "Agent #47 can skip.\n",
      "Agent #29 can skip.\n",
      "Agent #35 can skip.\n",
      "Agent #48 can skip.\n",
      "Agent #36 can skip.\n",
      "Agent #49 can skip.\n",
      "Agent #50 can skip.\n",
      "Agent #37 can skip.\n",
      "Agent #51 can skip.\n",
      "Agent #38 can skip.\n",
      "Agent #39 can skip.\n",
      "Agent #52 can skip.\n",
      "Agent #60 can skip.\n",
      "Agent #53 can skip.\n",
      "Agent #54 can skip.\n",
      "Agent #40 can skip.\n",
      "Agent #61 can skip.\n",
      "Agent #41 can skip.\n",
      "Agent #62 can skip.\n",
      "Agent #42 can skip.\n",
      "Agent #55 can skip.\n",
      "Agent #75 can skip.\n",
      "Agent #56 can skip.\n",
      "Agent #43 can skip.\n",
      "Agent #57 can skip.\n",
      "Agent #44 can skip.\n",
      "Agent #76 can skip.\n",
      "Agent #58 can skip.\n",
      "Agent #63 can skip.\n",
      "Agent #77 can skip.\n",
      "Agent #59 can skip.\n",
      "Agent #78 can skip.\n",
      "Agent #79 can skip.\n",
      "Agent #80 can skip.\n",
      "Agent #81 can skip.\n",
      "Agent #82 can skip.\n",
      "Agent #83 can skip.\n",
      "Agent #90 can skip.\n",
      "Agent #64 can skip.\n",
      "Agent #65 can skip.\n",
      "Agent #84 can skip.\n",
      "Agent #91 can skip.\n",
      "Agent #66 can skip.\n",
      "Agent #92 can skip.\n",
      "Agent #93 can skip.\n",
      "Agent #85 can skip.\n",
      "Agent #67 can skip.\n",
      "Agent #86 can skip.\n",
      "Agent #94 can skip.\n",
      "Agent #68 can skip.\n",
      "Agent #95 can skip.\n",
      "Agent #87 can skip.\n",
      "Agent #69 can skip.\n",
      "Agent #96 can skip.\n",
      "Agent #88 can skip.\n",
      "Agent #89 can skip.\n",
      "Agent #97 can skip.\n",
      "Agent #70 can skip.\n",
      "Agent #98 can skip.\n",
      "Agent #71 can skip.\n",
      "Agent #99 can skip.\n",
      "Agent #100 can skip.\n",
      "Agent #72 can skip.\n",
      "Agent #101 can skip.\n",
      "Agent #102 can skip.\n",
      "Agent #103 can skip.\n",
      "Agent #104 can skip.\n",
      "Agent #73 can skip.\n",
      "Agent #74 can skip.\n",
      "Time Taken (Seconds): 3383.0770580768585\n",
      "Results so far: [(-100.0, -1.0, -57.33611111111111), (-100.0, -1.0, -41.95), (-100.0, 1.0, -36.55437665782493), (-100.0, 1.0, -33.939153439153436), (-100.0, 8.0, -32.61498708010336), (-100.0, 8.0, -32.189473684210526), (-100.0, 21.0, -30.205655526992288), (-100.0, 21.0, -27.34805194805195), (-100.0, 17.0, -30.608465608465607), (-100.0, 17.0, -27.870558375634516), (-100.0, 17.0, -25.732647814910024), (-100.0, 17.0, -29.68831168831169), (-100.0, 17.0, -26.455470737913487), (-100.0, 17.0, -23.83812010443864), (-100.0, 17.0, -28.381074168797955), (-100.0, 17.0, -31.148541114058354), (-100.0, 17.0, -30.402564102564103), (-100.0, 17.0, -29.69309462915601)]\n",
      "Agent #105 can skip.\n",
      "Agent #106 can skip.\n",
      "Agent #107 can skip.\n",
      "Agent #108 can skip.\n",
      "Agent #109 can skip.\n",
      "Agent #110 can skip.\n",
      "Agent #111 can skip.\n",
      "Agent #112 can skip.\n",
      "Agent #113 can skip.\n",
      "Agent #120 can skip.\n",
      "Agent #114 can skip.\n",
      "Agent #115 can skip.\n",
      "Agent #121 can skip.\n",
      "Agent #116 can skip.\n",
      "Agent #122 can skip.\n",
      "Agent #117 can skip.\n",
      "Agent #118 can skip.\n",
      "Agent #123 can skip.\n",
      "Agent #124 can skip.\n",
      "Agent #119 can skip.\n",
      "Agent #125 can skip.\n",
      "Agent #135 can skip.\n",
      "Agent #126 can skip.\n",
      "Agent #127 can skip.\n",
      "Agent #136 can skip.\n",
      "Agent #137 can skip.\n",
      "Agent #128 can skip.\n",
      "Agent #138 can skip.\n",
      "Agent #139 can skip.\n",
      "Agent #140 can skip.\n",
      "Agent #129 can skip.\n",
      "Agent #141 can skip.\n",
      "Agent #142 can skip.\n",
      "Agent #130 can skip.\n",
      "Agent #143 can skip.\n",
      "Agent #131 can skip.\n",
      "Agent #132 can skip.\n",
      "Agent #144 can skip.\n",
      "Agent #133 can skip.\n",
      "Agent #145 can skip.\n",
      "Agent #134 can skip.\n",
      "Agent #146 can skip.\n",
      "Agent #147 can skip.\n",
      "Agent #148 can skip.\n",
      "Agent #149 can skip.\n",
      "Agent #150 can skip.\n",
      "Agent #151 can skip.\n",
      "Agent #152 can skip.\n",
      "Agent #153 can skip.\n",
      "Agent #154 can skip.\n",
      "Agent #155 can skip.\n",
      "Agent #156 can skip.\n",
      "Agent #157 can skip.\n",
      "Agent #158 can skip.\n",
      "Agent #159 can skip.\n",
      "Agent #165 can skip.\n",
      "Agent #160 can skip.\n",
      "Agent #161 can skip.\n",
      "Agent #166 can skip.\n",
      "Agent #162 can skip.\n",
      "Agent #167 can skip.\n",
      "Agent #163 can skip.\n",
      "Agent #168 can skip.\n",
      "Agent #164 can skip.\n",
      "Agent #169 can skip.\n",
      "Agent #170 can skip.\n",
      "Agent #171 can skip.\n",
      "Agent #172 can skip.\n",
      "Agent #173 can skip.\n",
      "Agent #174 can skip.\n",
      "Agent #175 can skip.\n",
      "Agent #176 can skip.\n",
      "Agent #177 can skip.\n",
      "Agent #178 can skip.\n",
      "Agent #179 can skip.\n",
      "Agent #180 can skip.\n",
      "Agent #181 can skip.\n",
      "Agent #182 can skip.\n",
      "Agent #183 can skip.\n",
      "Agent #184 can skip.\n",
      "Agent #185 can skip.\n",
      "Agent #186 can skip.\n",
      "Agent #187 can skip.\n",
      "Agent #188 can skip.\n",
      "Agent #189 can skip.\n",
      "Agent #190 can skip.\n",
      "Agent #191 can skip.\n",
      "Agent #192 can skip.\n",
      "Agent #193 can skip.\n",
      "Agent #194 can skip.\n",
      "Agent #195 can skip.\n",
      "Agent #196 can skip.\n",
      "Agent #197 can skip.\n",
      "Agent #198 can skip.\n",
      "Agent #199 can skip.\n",
      "Agent #200 can skip.\n",
      "Agent #201 can skip.\n",
      "Agent #202 can skip.\n",
      "Agent #203 can skip.\n",
      "Agent #204 can skip.\n",
      "Agent #205 can skip.\n",
      "Agent #206 can skip.\n",
      "Agent #207 can skip.\n",
      "Agent #210 can skip.\n",
      "Agent #208 can skip.\n",
      "Agent #209 can skip.\n",
      "Agent #211 can skip.\n",
      "Agent #212 can skip.\n",
      "Agent #213 can skip.\n",
      "Agent #270 | Ep #0 | Score: -100.0\n",
      "Agent #255 | Ep #0 | Score: -100.0\n",
      "Agent #285 | Ep #0 | Score: -25.0\n",
      "Agent #225 | Ep #0 | Score: -54.0\n",
      "Agent #214 | Ep #0 | Score: -30.0\n",
      "Agent #240 | Ep #0 | Score: -40.0\n",
      "Agent #300 | Ep #0 | Score: -10.0\n",
      "Agent #271 | Ep #0 | Score: -51.0\n",
      "Agent #256 | Ep #0 | Score: -31.0\n",
      "Agent #226 | Ep #0 | Score: -41.0\n",
      "Agent #286 | Ep #0 | Score: -30.0\n",
      "Agent #241 | Ep #0 | Score: -29.0\n",
      "Agent #215 | Ep #0 | Score: -31.0\n",
      "Agent #301 | Ep #0 | Score: -17.0\n",
      "Agent #272 | Ep #0 | Score: -27.0\n",
      "Agent #257 | Ep #0 | Score: -42.0\n",
      "Agent #242 | Ep #0 | Score: -52.0\n",
      "Agent #287 | Ep #0 | Score: -22.0\n",
      "Agent #227 | Ep #0 | Score: -18.0\n",
      "Agent #216 | Ep #0 | Score: -54.0\n",
      "Agent #302 | Ep #0 | Score: -54.0\n",
      "Agent #273 | Ep #0 | Score: -41.0\n",
      "Agent #288 | Ep #0 | Score: -95.0\n",
      "Agent #258 | Ep #0 | Score: -24.0\n",
      "Agent #217 | Ep #0 | Score: -100.0\n",
      "Agent #228 | Ep #0 | Score: -54.0\n",
      "Agent #243 | Ep #0 | Score: -50.0\n",
      "Agent #274 | Ep #0 | Score: -30.0\n",
      "Agent #303 | Ep #0 | Score: -37.0\n",
      "Agent #304 | Ep #0 | Score: -100.0\n",
      "Agent #259 | Ep #0 | Score: -30.0\n",
      "Agent #289 | Ep #0 | Score: -12.0\n",
      "Agent #218 | Ep #0 | Score: -32.0\n",
      "Agent #229 | Ep #0 | Score: -35.0\n",
      "Agent #244 | Ep #0 | Score: -39.0\n",
      "Agent #275 | Ep #0 | Score: -22.0\n",
      "Agent #219 | Ep #0 | Score: -100.0\n",
      "Agent #260 | Ep #0 | Score: -100.0\n",
      "Agent #290 | Ep #0 | Score: -100.0\n",
      "Agent #305 | Ep #0 | Score: -41.0\n",
      "Agent #245 | Ep #0 | Score: -38.0\n",
      "Agent #230 | Ep #0 | Score: -36.0\n",
      "Agent #220 | Ep #0 | Score: -8.0\n",
      "Agent #276 | Ep #0 | Score: -54.0\n",
      "Agent #261 | Ep #0 | Score: -100.0\n",
      "Agent #291 | Ep #0 | Score: -100.0\n",
      "Agent #306 | Ep #0 | Score: -38.0\n",
      "Agent #231 | Ep #0 | Score: -1.0\n",
      "Agent #246 | Ep #0 | Score: -36.0\n",
      "Agent #292 | Ep #0 | Score: -10.0\n",
      "Agent #262 | Ep #0 | Score: -36.0\n",
      "Agent #277 | Ep #0 | Score: -54.0\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "import time\n",
    "\n",
    "tStart = time.time()\n",
    "\n",
    "trainer = Trainer(actions=range(7), teamPopSize=360)\n",
    "\n",
    "processes = 7 \n",
    "man = mp.Manager()\n",
    "pool = mp.Pool(processes=processes, maxtasksperchild=1)\n",
    "    \n",
    "allScores = [] # track all scores each generation\n",
    "\n",
    "for gen in range(30): # do 30 generations of training\n",
    "    scoreList = man.list()\n",
    "    \n",
    "    # get agents, noRef to not hold reference to trainer in each one\n",
    "    # don't need reference to trainer in multiprocessing\n",
    "    agents = trainer.getAgents() # swap out agents only at start of generation\n",
    "\n",
    "    # run the agents\n",
    "    pool.map(runAgent, \n",
    "        [(agent, 'Boxing-v0', scoreList, 1, 18000)\n",
    "        for agent in agents])\n",
    "    \n",
    "    # apply scores, must do this when multiprocessing\n",
    "    # because agents can't refer to trainer\n",
    "    teams = trainer.applyScores(scoreList)\n",
    "    # important to remember to set tasks right, unless not using task names\n",
    "    # task name set in runAgent()\n",
    "    trainer.evolve(task='Boxing-v0-18000') # go into next gen\n",
    "    \n",
    "    # an easier way to track stats than the above example\n",
    "    scoreStats = trainer.fitnessStats\n",
    "    allScores.append((scoreStats['min'], scoreStats['max'], scoreStats['average']))\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    print('Time Taken (Seconds): ' + str(time.time() - tStart))\n",
    "    print('Results so far: ' + str(allScores))\n",
    "    \n",
    "clear_output(wait=True)\n",
    "print('Time Taken (Seconds): ' + str(time.time() - tStart))\n",
    "print('Results:\\nMin, Max, Avg')\n",
    "for score in allScores:\n",
    "    print(score[0],score[1],score[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the results above, boxing is a particularly difficult game that takes a while for improvement. The max score will sometimes take a dip because the root team that had the max score may become a child of another root team during a mutation, making it no longer a root team. But this new mutation either shortly disapears if it is no good and the old root team is restored, or, it will perform well and stay for a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Tournament Selection (In progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken (Seconds): 45202.94136309624\n",
      "Results: [(0, 16905.0, 50.91867469879518), (0, 31521.0, 99.43533123028391), (0, 47733.0, 157.01644736842104), (0, 59262.0, 196.2317880794702), (0, 63903.0, 215.16161616161617), (0, 66339.0, 230.34375), (0, 68754.0, 242.09154929577466), (0, 68460.0, 244.5), (0, 73290.0, 251.8556701030928), (0, 70371.0, 256.8284671532847)]\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "import time\n",
    "\n",
    "tStart = time.time()\n",
    "\n",
    "lock = mp.Lock()\n",
    "\n",
    "trainer = TpgTrainer(actions=range(7), teamPopSizeInit=360)\n",
    "\n",
    "processes = 4 # how many to run concurrently (4 is best for my local desktop)\n",
    "\n",
    "m = mp.Manager()\n",
    "envQueue = m.Queue()\n",
    "# each process needs its own environment\n",
    "for i in range(processes):\n",
    "    envQueue.put(gym.make('Assault-v0'))\n",
    "\n",
    "pool = mp.Pool(processes=processes)\n",
    "    \n",
    "summaryScores = [] # record score summaries for population\n",
    "    \n",
    "# tournament loop \n",
    "# 450 tournaments of size 8 approximately equals 10 generations\n",
    "# *at pop size 360\n",
    "for tourn in range(450): \n",
    "    scoreQueue = m.Queue() # hold agents when finish, to actually apply score\n",
    "\n",
    "    # run tournament\n",
    "    # skipTasks=[] so we get all agents, even if already scored,\n",
    "    # just to report the obtained score for all agents.\n",
    "    pool.map(runAgent, \n",
    "                 [(agent, envQueue, scoreQueue) \n",
    "                  for agent in trainer.getTournamentAgents()])\n",
    "    \n",
    "    scores = [] # convert scores into list\n",
    "    while not scoreQueue.empty():\n",
    "        scores.append(scoreQueue.get())\n",
    "    \n",
    "    # apply scores\n",
    "    teams = trainer.applyScores(scores) # get teams from trainer\n",
    "    trainer.evolve(tourneyTeams=teams,tasks=[]) # evolve tournament players\n",
    "    \n",
    "    # report score once equivalent to a generation\n",
    "    if (tourn+1) % 45 == 0:\n",
    "        scoreStats = trainer.generateScoreStats()\n",
    "\n",
    "        # at end of generation, make summary of scores\n",
    "        summaryScores.append((scoreStats['min'], \n",
    "                        scoreStats['max'],\n",
    "                        scoreStats['average'])) # min, max, avg\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        print('Time Taken (Seconds): ' + str(time.time() - tStart))\n",
    "        print('Results so far: ' + str(summaryScores))\n",
    "    \n",
    "clear_output(wait=True)\n",
    "print('Time Taken (Seconds): ' + str(time.time() - tStart))\n",
    "print('Results: ' + str(summaryScores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:oaigym] *",
   "language": "python",
   "name": "conda-env-oaigym-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
