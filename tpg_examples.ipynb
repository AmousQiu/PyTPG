{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPG Examples\n",
    "This document shows how to use the PyTPG API. We make use of OpenAI Gym to run examples, and we assume you already have PyTPG installed, see the readme for installation instructions for PyTPG."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "# imports to run OpenAI Gym in Jupyter\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "# how to render in Jupyter: \n",
    "# https://stackoverflow.com/questions/40195740/how-to-run-openai-gym-render-over-a-server\n",
    "# https://www.youtube.com/watch?v=O84KgRt6AJI\n",
    "def show_state(env, step=0, name='', info=''):\n",
    "    plt.figure(3)\n",
    "    plt.clf()\n",
    "    plt.imshow(env.render(mode='rgb_array'))\n",
    "    plt.title(\"%s | Step: %d %s\" % (name, step, info))\n",
    "    plt.axis('off')\n",
    "\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    \n",
    "# transforms the state into what the tpg agent can use.\n",
    "# From 3D to 1D, taking only red data (from rgb array)\n",
    "def getState(state):\n",
    "    state2 = []\n",
    "    for x in state:\n",
    "        for y in x:\n",
    "            state2.append(y[0])\n",
    "            \n",
    "    return state2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env = gym.make('Assault-v0') # make the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(7)\n"
     ]
    }
   ],
   "source": [
    "print(env.action_space) # learn size of action space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import to do training\n",
    "from tpg.tpg_trainer import TpgTrainer\n",
    "# import to run an agent (always needed)\n",
    "from tpg.tpg_agent import TpgAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generational Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import time # for tracking time\n",
    "\n",
    "tStart = time.time()\n",
    "\n",
    "# first create an instance of the TpgTrainer\n",
    "# this creates the whole population and everything\n",
    "trainer = TpgTrainer(actions=range(7), teamPopSizeInit=50)\n",
    "\n",
    "curScores = [] # hold scores in a generation\n",
    "summaryScores = [] # record score summaries for each gen (min, max, avg)\n",
    "\n",
    "# 5 generations isn't much (not even close), but some improvements\n",
    "# should be seen.\n",
    "for gen in range(5): # generation loop\n",
    "    curScores.clear() # new list per gen\n",
    "    \n",
    "    while True: # loop to go through agents\n",
    "        teamNum = trainer.remainingAgents()\n",
    "        agent = trainer.getNextAgent()\n",
    "        if agent is None:\n",
    "            break # no more agents, so proceed to next gen\n",
    "        \n",
    "        state = env.reset() # get initial state and prep environment\n",
    "        score = 0\n",
    "        for i in range(200): # run episodes that last 200 frames\n",
    "            show_state(env, i, 'Assault', 'Gen #' + str(gen) + \n",
    "                       ', Team #' + str(teamNum) +\n",
    "                       ', Score: ' + str(score)) # render env\n",
    "            \n",
    "            act = agent.act(getState(state)) # get action from agent\n",
    "            \n",
    "            # feedback from env\n",
    "            state, reward, isDone, debug = env.step(act)\n",
    "            score += reward # accumulate reward in score\n",
    "            if isDone:\n",
    "                break # end early if losing state\n",
    "                \n",
    "        agent.reward(score) # must reward agent\n",
    "        curScores.append(score) # store score\n",
    "            \n",
    "    # at end of generation, make summary of scores\n",
    "    summaryScores.append((min(curScores), max(curScores),\n",
    "                    sum(curScores)/len(curScores))) # min, max, avg\n",
    "    trainer.evolve()\n",
    "    \n",
    "print('Time Taken (Seconds): ' + str(time.time() - tStart))\n",
    "print('Results:\\nMin, Max, Avg')\n",
    "for result in summaryScores:\n",
    "    print(result[0],result[1],result[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generational Selection with Multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for env...\n",
      "5\n",
      "Waiting for env...\n",
      "4\n",
      "Waiting for env...\n",
      "3\n",
      "Waiting for env...\n",
      "2\n",
      "Waiting for env...\n",
      "1\n",
      "Waiting for env...\n",
      "0\n",
      "Waiting for env...\n",
      "0\n",
      "Waiting for env...\n",
      "0\n",
      "Waiting for env...\n",
      "0\n",
      "Waiting for env...\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-139:\n",
      "Process ForkPoolWorker-135:\n",
      "Process ForkPoolWorker-137:\n",
      "Process ForkPoolWorker-136:\n",
      "Process ForkPoolWorker-138:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-aa64baf03bbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m     pool.starmap(runAgent, \n\u001b[1;32m     48\u001b[0m                  [(agent, envQueue, curScores) \n\u001b[0;32m---> 49\u001b[0;31m                   for agent in trainer.getAllAgents()])\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;31m# at end of generation, make summary of scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mstarmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mbecomes\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         '''\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     def starmap_async(self, func, iterable, chunksize=None, callback=None,\n",
      "\u001b[0;32m~/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/oaigym/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/oaigym/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/pool.py\", line 47, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-aa64baf03bbf>\", line 21, in runAgent\n",
      "    env = eq.get() # get an environment\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/pool.py\", line 47, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n",
      "  File \"<string>\", line 2, in get\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/pool.py\", line 47, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/pool.py\", line 47, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-15-aa64baf03bbf>\", line 21, in runAgent\n",
      "    env = eq.get() # get an environment\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/managers.py\", line 757, in _callmethod\n",
      "    kind, result = conn.recv()\n",
      "  File \"<ipython-input-15-aa64baf03bbf>\", line 21, in runAgent\n",
      "    env = eq.get() # get an environment\n",
      "  File \"<ipython-input-15-aa64baf03bbf>\", line 21, in runAgent\n",
      "    env = eq.get() # get an environment\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/pool.py\", line 47, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n",
      "  File \"<string>\", line 2, in get\n",
      "  File \"<string>\", line 2, in get\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"<string>\", line 2, in get\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/managers.py\", line 757, in _callmethod\n",
      "    kind, result = conn.recv()\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/managers.py\", line 757, in _callmethod\n",
      "    kind, result = conn.recv()\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/managers.py\", line 757, in _callmethod\n",
      "    kind, result = conn.recv()\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-15-aa64baf03bbf>\", line 21, in runAgent\n",
      "    env = eq.get() # get an environment\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"<string>\", line 2, in get\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/managers.py\", line 757, in _callmethod\n",
      "    kind, result = conn.recv()\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "import time\n",
    "\n",
    "tStart = time.time()\n",
    "\n",
    "trainer = TpgTrainer(actions=range(7), teamPopSizeInit=50)\n",
    "\n",
    "m = mp.Manager()\n",
    "envQueue = m.Queue()\n",
    "# each worker needs its own environment\n",
    "for i in range(workers):\n",
    "    envQueue.put(gym.make('Assault-v0'))\n",
    "    \n",
    "summaryScores = [] # record score summaries for each gen (min, max, avg)\n",
    "\n",
    "# run agent in function to work with multiprocessing\n",
    "def runAgent(agent, eq, sq):\n",
    "    print('Waiting for env...')\n",
    "    print(eq.qsize())\n",
    "    env = eq.get() # get an environment\n",
    "    print('Agent #' + str(agent.getId()) + ' starting.')\n",
    "    state = env.reset() # get initial state and prep environment\n",
    "    score = 0\n",
    "    for i in range(200): # run episodes that last 200 frames\n",
    "        act = agent.act(getState(state)) # get action from agent\n",
    "\n",
    "        # feedback from env\n",
    "        state, reward, isDone, debug = env.step(act)\n",
    "        score += reward # accumulate reward in score\n",
    "        if isDone:\n",
    "            break # end early if losing state\n",
    "\n",
    "    agent.reward(score) # must reward agent\n",
    "    sq.put(score) # store score\n",
    "    \n",
    "    print('Agent #' + str(agent.getId()) + ' finished with score ' + str(score))\n",
    "    \n",
    "    e.put(env) # put environment back\n",
    "    \n",
    "    \n",
    "for gen in range(5): # generation loop\n",
    "    curScores = m.Queue() # hold scores in a generation (queue so thread safe)\n",
    "    \n",
    "    # run generation\n",
    "    pool = mp.Pool(processes=5)\n",
    "    pool.starmap(runAgent, \n",
    "                 [(agent, envQueue, curScores) \n",
    "                  for agent in trainer.getAllAgents()])\n",
    "            \n",
    "    # at end of generation, make summary of scores\n",
    "    scoreRec.append((min(list(curScores)), max(list(curScores)),\n",
    "                    sum(list(curScores))/len(curScores))) # min, max, avg\n",
    "    \n",
    "print('Time Taken (Seconds): ' + str(time.time() - tStart))\n",
    "print('Results: ' + str(scoreRec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Tournament Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:oaigym]",
   "language": "python",
   "name": "conda-env-oaigym-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
