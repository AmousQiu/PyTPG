{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPG Examples\n",
    "This document shows how to use the PyTPG API. We make use of OpenAI Gym to run examples, and we assume you already have PyTPG installed, see the readme for installation instructions for PyTPG."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from IPython.display import clear_output\n",
    "# imports to run OpenAI Gym in Jupyter\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "# how to render in Jupyter: \n",
    "# https://stackoverflow.com/questions/40195740/how-to-run-openai-gym-render-over-a-server\n",
    "# https://www.youtube.com/watch?v=O84KgRt6AJI\n",
    "def show_state(env, step=0, name='', info=''):\n",
    "    plt.figure(3)\n",
    "    plt.clf()\n",
    "    plt.imshow(env.render(mode='rgb_array'))\n",
    "    plt.title(\"%s | Step: %d %s\" % (name, step, info))\n",
    "    plt.axis('off')\n",
    "\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    \n",
    "# transforms the state into what the tpg agent can use.\n",
    "# From 3D to 1D, taking only red data (from rgb array)\n",
    "def getState(state):\n",
    "    state2 = []\n",
    "    for x in state:\n",
    "        for y in x:\n",
    "            state2.append(y[0])\n",
    "            \n",
    "    return state2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryan/git/gym/gym/__init__.py:22: UserWarning: DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.\n",
      "  warnings.warn('DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.')\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('Assault-v0') # make the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(7)\n"
     ]
    }
   ],
   "source": [
    "print(env.action_space) # learn size of action space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import to do training\n",
    "from tpg.tpg_trainer import TpgTrainer\n",
    "# import to run an agent (always needed)\n",
    "from tpg.tpg_agent import TpgAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Basic Generational Selection (with graphics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f72d27e17d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken (Seconds): 3538.80792689\n",
      "Results:\n",
      "Min, Max, Avg\n",
      "(0.0, 147.0, 18.06)\n",
      "(0.0, 168.0, 35.0)\n",
      "(0.0, 168.0, 55.0)\n",
      "(0.0, 168.0, 77.5)\n",
      "(0.0, 168.0, 104.5)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUQAAAEICAYAAAAncI3RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAEzlJREFUeJzt3Xu0nFV5x/Hvw/1mEjQEkJsXRI20QoAlssRGtHKoCrJcTVGphGohbSlLpKtFRQXqDa03ikKx2LSNLabYImqbRSnFcmkqEuMtQgtaEAxquERBoQi7f+xnkjeTmTlzck5mzuX7WeusM/Pud/bs9513frP3fuecN0opSJJgm2E3QJImCwNRkpKBKEnJQJSkZCBKUjIQJSlNuUCMiOsj4i1jWH9xRCzdik2SNE30HYgZRA9GxI5bs0FjkWF34zjreElE3BwR6yPigYi4KSKOmKj6x9iWRdmWn0fE9R3KXxMR346Ih3O9+Y2yHSPiYxHxw3ydPhUR2/d4roiIMyLim/l89+VrfNJW2rzmc381Ig6KiGdFxKou6zwnIh6NiGV91vkvuV8ejojHI+L/Gvcvndgt2HIRcXVEvDQidouIe9rKLoqIOyPiZxGxJiJeP4Z6nxYRfxMRP4qIn0bE7RHxtonfgvGJiAvzGH4iIs7pUH5KRNydr9uVETG7UXZFRDzWeF0fGuW5utbVTV+BGBHPAI4GCnB8P4+ZCiJiFvAl4M+BpwL7AOcDjw2pSQ8AHwc+2F4QEc8BPgssAeYAXwSujojtcpVzgMOBg4GDgAXAuT2e6yLgrcDZwNOo234uMDIRG9JNhvQBwP8AhwEdAxH4JHBLv/WWUo4rpexWStmNup8+1LpfSlky3nZPoEOp23wosLqt7KfAccBs4DTg0og4rM96LwaC+trPAU4Evj8RDW5pHGvjcTv1mPvXDvUfSj0ufwvYm7o9n2hb7U8br+ucHm3tp67NlVJG/QHeDdwEfBT4UlvZbwBrgJ8B9wJ/lMvnUsPmIeob/QZgmyw7B7gzH7MGOLFR33nAssb9Z1CDeLu8fz3wFuD5wKPAE8DDwENd2r4YWNql7PAej+tYP7Aj8GfA3cCPgEuBnbNsIXAP8A5gHfC/wBv72cdtz/0W4Pq2ZWcA/9y4vw3wC+Dlef9rwKJG+RuAH3Sp/6DcrsNHacds4HJgbb627wW2bezXG3NfPEh98x3Xx7YdCvx73r4Q+P0O65wELG8/Fsaw/5YC7+2w/ETgm3lM3gDMbzvGv5/H5LeBVzXKlgDXUUNnPTXMD6eG1r15HJzUR7v2Btbk7bOAC0ZZ/xrgD/rc5juAkR7lL8xteBC4Dzg7l+9M/fBZm8fuh4Hts2wk631XbuOnR9uPY3iNrgTOaVv2UeAzjfvz8xjfKe9fAZzbZ/096+r20++Q+U3UT93PAsdGxJ6NssuB00spT6H2Tq7L5WfnDt4D2JMaEq2/E7yT2uOcTe2RLYuIvftsCwCllO9SD9T/LKN8WvTw38ATEfHXEXFcROzeR/0fpAbKIcCB1J7Vuxt17kX9MNgHOAW4LCKeCxARb4iIb25BOzuJ/Dm4R/m+XYYJx1DD8mujPMdS4JfU7TwUeCU1rFteRP3Enwt8CLg8IqJjYyJOzSHOTcCL8/bZwIUR8VBEPDPXmwVcAEzocC8ijgQ+BZxK7RH/LXBVo9dzO3AU9Zi8ELgiIuY2qjgauJk6krgK+Dz1Q/OZwO8Cl0TETl2e+1W5vXcAB+btC4G35bYf2eExu1F7+d/pcxNXUvflKRFxYFtduwPXAv9IPT4PAv4ji88HfhX4FWqPfSHwx42HPwPYHtgPOHO0/RgRl0fER/tsc7sXAN9o3SmlrAG2BZ7dWOesiLg/Ir4WEb1Gq/3Utbk+kvYlwOPA3Lx/G3BWo/xu4HRgVtvjLgC+ABzYx3OsBk7I2+fRRw8xby8Gbhyl7sV06SFm+fOpb/x7qG/+q4E9O9VPDZlHgGc3lr0Y+H7eXph17NooXw68a4yfnp16iM/L514I7ED91H4SeHuWv5caNntQD/r/yv22d4f6zwVWti27h/qJ/yh1SLsndepg58Y6r2dj724xcEejbJd8vr1G2bYbqB8m++frHm3lnwD+pNOxMIb9t5S2HiLwV8A725bdBbyoSx23Acfm7SXAtxplR+S2zm4sewR43ijtuhI4lhq6twM7dFkvqL2hq8awzbtSP5hX5zF4O/CKLDuV+sHe6XH3Asc07p8A3Ja3R3K7tt/S/TjKvmjvId4ELG5bdj9wZN4+DNidGtAnUEduHUc5o9XV7aefHuIpwDWllHV5/+9yWcvrqMPmuyLiKxHx4lz+Yeon4jUR8b3mBGpEvCkiVuen40PUXk7z03hgSinfLaUsLqXsm+14OnUer5M9qG/8WxttX5HLWx4spTzSuH9X1jnedt5G3e8XU4c3c6nTDa2J+fcBX6e+IW6m9mIepw512t1PHb41698369yR+oY8gHrgrW1s618A8xoPu6/x+J/nzd3anywinpp1rKf2wq6nvmGfCzwYEW/N9Q4BXgF8bNQdMnYHAO9obUtuzx7UnjwR8eY8wdQqO5BNj8nmfvwF8FgpZX3bss22Petel9t+IvA54IfUD/ofR8QHOjzkomzvyf1uXCnlkVLKBaWUQ6g9ty8Cn4+Ip1B7d3d2aFdQPzzvaiy+i9wn6b5SyuON+z334zg9DMxqWzaLOo1BKeXWUsqDpZTHSylfoIbqiVtSVzc9J0kjYmdgEbBtRLQO/h2BORHxwlLKN0optwAn5GT5GdQe0X6llJ9Rh0RnR8TBwHURcQs1JD8NvJz6qfVERKymvgmhfiLt0mjGXj2aOKH/qqeUclvUr+ic3qX+ddQD/wWllHu7VLN7ROzaCMX9qXNSE9G+K6kHARExB3gzeeKhlPIL6v4/I8tPA24tpTzZoarrgIsj4vDSfdj8A2oPcW4p5ZfjbPcD1GPmJOBlpZTTI+KfgE+WUq5trLqQGhR358h7N+qxN7+UsmA8baBuz5dLKR9pL4iIg6gn1o4BvlpKeTIibmPjMTkupZS5EbGQOrI6ISIuAW4qpWx2Bj0iLqSOyl5WSnl4C59vfUR8kPr+25+67cd1WK/k+/oANgbm/tRe44bV2h7WdT9OgO9Q5zoBiIgXUHu7m4V5o23dXqOx1gWMfpb5tdTJ9/nUYc4h1CHmDcCbImKHiHhjRMzOT5GfUodxRMSrI+LA/BRan/U8Se3aF+Anud6pbDoPthp4aUTsn/Nfb+/Rvh9R58l2GGU7OoqI50XE2RGxb97fjzosXNmp/gyXTwMfi4h5+Zh9IuLYtqrPz31zNPBq4B/6bM+2OQ+1HbBNROwUja/ORMRhuc4ewGXA1dlzbLXj6VEdSR1Sv6fT85RSbqf29q6IiF+PiJ0jYltq7621zlrqpP5HImJWRGwTEc+OiF/rZ1u6aJ5VPhS4ta38MuocT+tYuxT4MnWY2doHJcNlrC4D/jAiDs99tFtEHB8Ru1CD90nqMblNRCyh9hAnUnPbF1BPgm0iIs6nfovjlaWUzb5SEvWrUR2/FhUR50XEgojYPjsyZ1I/wO+gjhYOjIjfy+NyVuRXy4C/B94T9Ws784B3Ar2+6tRrP44q27cTNXu2y2O8lUPLgNdFxIuizqFeAHyulPJoRGwXESdGxK75HngV8JvUnnAnXevq2cBRxvkrgI90WL6IOlzaIdd5kBqGtwAvyXXOop5lfYQ6rHtX4/Hvo555Xkc9G/QVcl4wyz9Jnc+6gzph3W0OcQfqG+YBYF2XbVhM97PM+1B7tPdmO++lBsWsbvUDOwHvB76X2/xd4MwsW5jb+s7ctruB32483xuB7/TY34tzW5s/SxvlN1K7/A9kO5tzlS/N/f1z6nC059lt6ifrmcC3qL3etfk6LGLjtwFmA5fkNq2nDslParT1xrY6Cz3mjKk90yOoQ7o7e7Uv1z+PTeeT98t9/rRRHreUzmeZj6eG8HrqsPUKNn5DoHW2/CfUEx4rgZOzbAlwbaOeg4FH2+peR4+z9tSpptdQJ/Z/3NrHjfIdc/89Rh3utX7eluW75DH6rC71X8DGb3vcD/wbcESj/JB8fR/K1/qsRr2XUN/PP6S+H3fIshEa88R97selwMd77Icr2PwYP6lRvjiPt0eoJ65m5/LtqfOC6/MY+Drwurb993DbNnesq9dP5AOnrYhYDCwspSwewHMtpL6B993azzUTRcTJ1OmKXqOGaSkiXkH9kDt12G2Zzibii5bSQJQOc24zRalzrdeOuqLGZSYE4mrqMEGSepr2Q2ZJ6teU+283krS1zIQh86QTEXbL1bdSyoR8H1Kjs4coSclAlKRkIEpSMhAlKRmIkpQMRElKBqIkJQNRkpKBKEnJQJSkZCBKUjIQJSkZiJKUDERJSgaiJCUDUZKSgShJyUCUpGQgSlIyECUpGYiSlAxESUoGoiQlA1GSkoEoSclAlKRkIEpSMhAlKRmIkpQMRElKBqIkJQNRkpKBKElpu2E3QFPXmpNP3nB7/rJlE1LWKu+2vNPjmst71SuNxh6itkgrhFrB0wylLS3rdL/fx81ftmyTH2lLGIiaNLqFoTQoBqImjS3t3bUPnw1WbSkDUZKSgagpzx6hJkqUUobdhhknIqbFTp/os8yjnS0ez5nrqayUEsNuw0xhIA7BdAlEDYaBODgOmSUpGYiSlAxESUoGoiQl/5ZZQ7FyZGTD7SNXrBhiS6SNPMs8BDPxLPMNHz+673WPfusNW7ElU49nmQfHQByCmRKIe/3O8eOu477PXD0BLZnaDMTBMRCHYLoH4pKRmye8zktXHDXhdU4VBuLgGIhDMF0D8eYztn5oHXXxxIftZGcgDo4nVTRu7UHYCq2bzzhqk9sTXSZNNANRE6ZTiHUKtPGUSVuTQ+YhmG5D5q0xZ9jLTJtPdMg8OAbiEEy3QGzZ67XnbfXnuO+qrf8ck42BODgOmTVxnrpq2C2QxsUe4hBM1x5iSz9fwm5++Xqs68809hAHx79llqRkD3EIpnsPsaX598otvf5ueazrzxT2EAfHQByCmRKIsDHkxhJsK0dGDMIGA3FwDMQhmEmBqPEzEAfHOURJSgaiJCUDUZKSgShJyUCUpGQgSlIyECUpGYiSlAxESUoGoiQlA1GSkoEoSclAlKRkIEpSMhAlKRmIkpQMRElKXoZ0mlqy92Ubbl+69rS+y6SZzB6iJCUDcRpasvdlG3p+l649bUOPsFvPsLlcmsm8yNQQDOIiU62QawVft/vNZZqcvMjU4BiIQzCIQFyxYAEjq1axYsGCjuWtsuZvTU4G4uA4ZJ5BDD2pN3uIQzCIHmL7BeK73W8u0+RkD3FwDMQh8EL1GgsDcXAcMktSMhAlKRmIkpQMRElKBqIkJQNRkpKBKEnJQJSkZCBKUjIQJSkZiJKUDERJSgaiJCUDUZPCunXrht0EyavuafIb7XIHXg5BE8UeoiQlA1GTWqcrCPa6iqBXENR4+B+zh8D/mL25devWMXfu3E2WtV8oq3VNmOaFs9qXTcfrxvgfswfHHqImhfYwbNcKxvarCLaWdQpLaaw8qaJJa868eR1/d7pQVrNc2lL2EDWptYde+xUCm+Ho1QM1Xs4hDoFziBoL5xAHxx6iJCUDUZKSgShJyUCUpGQgSlIyECUpGYiSlAxESUoGoiQlA1GSkoEoSclAlKRkIEpSMhAlKRmImnKa11UZS5k0GgNRkpKBqCml1ftrXYGvtay5vH1dqV/+x+wh8D9mb5nmVfi6XYGv0xX5pjr/Y/bg2EPUlNG6iNTIqlWsHBlh5cgIc+bNY2TVKubMm8fKkZENt1vrSGNhIGrKaV1Qqv3qe0euWLHhthed0pYwEDWltIKu2fvrdSU+aSycQxwC5xA1Fs4hDo49RElKBqIkJQNRkpKBKEnJQJSkZCBKUjIQJSkZiJKUDERJSgaiJCUDUZKSgShJyUCUpGQgSlIyECUpGYiSlAxESUoGoiQlA1GSkoEoSclAlKRkIEpSMhAlKRmIkpQMRElKBqIkJQNRkpKBKEnJQJSkZCBKUjIQJSkZiJKUDERJSgaiJCUDUZKSgShJyUCUpGQgSlIyECUpGYiSlAxESUoGoiQlA1GSkoEoSclAlKRkIEpSMhAlKRmIkpQMRElKBqIkJQNRkpKBKEnJQJSkZCBKUjIQJSkZiJKUDERJSgaihm5k6QgjS0eG3QzJQNRwjSwdYcXiFaxYvMJQ1NAZiBqaTgFoKGqYopQy7DbMOBHhTgfWrFnTtWz+/PkDbMnkVkqJYbdhprCHKElpu2E3QDPX95a9AYBXv381AF96xyGb3JcGzR6ihqZT8BmGGibnEIfAOUSNhXOIg+OQeQjO/Mtjht0ESR04ZJak5JB5CBwyaywcMg+OPURJSgaiJCVPqkxBy5cvZ9GiRcNuxqRx0SuvH3YT+nLmNQuH3QSNwkCcQpYvXw7AokWLNrktaWI4ZJ4iWgHY67ak8TEQJSkZiFNEc2jc7bak8TEQp5D28DMMpYllIE4hrfnC9t+SJoZ/qTIE/qWKxsK/VBkce4iSlAxESUoGoiQlA1GSkoEoSclAlKRkIEpSMhAlKRmIkpQMRElK/umeJCV7iJKUDERJSgaiJCUDUZKSgShJyUCUpGQgSlIyECUpGYiSlAxESUoGoiQlA1GSkoEoSclAlKRkIEpSMhAlKRmIkpQMRElKBqIkJQNRkpKBKEnJQJSkZCBKUvp/d2NWUUpNulgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f72d27e17d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import time # for tracking time\n",
    "\n",
    "tStart = time.time()\n",
    "\n",
    "# first create an instance of the TpgTrainer\n",
    "# this creates the whole population and everything\n",
    "trainer = TpgTrainer(actions=range(7), teamPopSizeInit=50)\n",
    "\n",
    "curScores = [] # hold scores in a generation\n",
    "summaryScores = [] # record score summaries for each gen (min, max, avg)\n",
    "\n",
    "# 5 generations isn't much (not even close), but some improvements\n",
    "# should be seen.\n",
    "for gen in range(5): # generation loop\n",
    "    curScores = [] # new list per gen\n",
    "    \n",
    "    while True: # loop to go through agents\n",
    "        teamNum = trainer.remainingAgents()\n",
    "        agent = trainer.getNextAgent()\n",
    "        if agent is None:\n",
    "            break # no more agents, so proceed to next gen\n",
    "        \n",
    "        # check if agent already has score\n",
    "        if agent.taskDone():\n",
    "            score = agent.getOutcome()\n",
    "        else:\n",
    "            state = env.reset() # get initial state and prep environment\n",
    "            score = 0\n",
    "            for i in range(200): # run episodes that last 200 frames\n",
    "                show_state(env, i, 'Assault', 'Gen #' + str(gen) + \n",
    "                           ', Team #' + str(teamNum) +\n",
    "                           ', Score: ' + str(score)) # render env\n",
    "\n",
    "                act = agent.act(getState(state)) # get action from agent\n",
    "\n",
    "                # feedback from env\n",
    "                state, reward, isDone, debug = env.step(act)\n",
    "                score += reward # accumulate reward in score\n",
    "                if isDone:\n",
    "                    break # end early if losing state\n",
    "\n",
    "            agent.reward(score) # must reward agent (if didn't already score)\n",
    "            \n",
    "        curScores.append(score) # store score\n",
    "            \n",
    "    # at end of generation, make summary of scores\n",
    "    summaryScores.append((min(curScores), max(curScores),\n",
    "                    sum(curScores)/len(curScores))) # min, max, avg\n",
    "    trainer.evolve()\n",
    "    \n",
    "#clear_output(wait=True)\n",
    "print('Time Taken (Seconds): ' + str(time.time() - tStart))\n",
    "print('Results:\\nMin, Max, Avg')\n",
    "for result in summaryScores:\n",
    "    print(result[0],result[1],result[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Generational Selection with Multiprocessing (no graphics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example is just to show a different way to run the API. It uses a different method to get the agents, doesn't use graphics, and uses multiprocessing. For a more in depth comparison of run performances with different configurations see {Section Name}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run agent in function to work with multiprocessing\n",
    "def runAgent(agenteqsqaq):\n",
    "    agent = agenteqsqaq[0] # get agent\n",
    "    eq = agenteqsqaq[1] # get environment queue\n",
    "    sq = agenteqsqaq[2] # get score queue\n",
    "    aq = agenteqsqaq[3] # get agent queue\n",
    "    \n",
    "    # check if agent already has score\n",
    "    if agent.taskDone():\n",
    "        print('already done task, skipping')\n",
    "        sq.put(agent.getOutcome()) # store score\n",
    "        return\n",
    "        \n",
    "    print('Waiting for env...')\n",
    "    print(eq.qsize())\n",
    "    env = eq.get() # get an environment\n",
    "    print('Agent #' + str(agent.getAgentNum()) + ' starting.')\n",
    "    state = env.reset() # get initial state and prep environment\n",
    "    score = 0\n",
    "    for i in range(200): # run episodes that last 200 frames\n",
    "        act = agent.act(getState(state)) # get action from agent\n",
    "\n",
    "        # feedback from env\n",
    "        state, reward, isDone, debug = env.step(act)\n",
    "        score += reward # accumulate reward in score\n",
    "        if isDone:\n",
    "            break # end early if losing state\n",
    "    lock.acquire()\n",
    "    agent.reward(score) # must reward agent\n",
    "    lock.release()\n",
    "    sq.put(score) # store score\n",
    "    \n",
    "    print('Agent #' + str(agent.getAgentNum()) + ' finished with score ' + str(score))\n",
    "    aq.put(agent)\n",
    "    eq.put(env) # put environment back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryan/git/gym/gym/__init__.py:22: UserWarning: DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.\n",
      "  warnings.warn('DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for env...\n",
      "4\n",
      "Agent #49 starting.\n",
      "Agent #49 finished with score 168.0\n",
      "Waiting for env...\n",
      "3\n",
      "Agent #45 starting.\n",
      "Agent #45 finished with score 189.0\n",
      "Waiting for env...\n",
      "3\n",
      "Agent #48 starting.\n",
      "Waiting for env...\n",
      "2\n",
      "Agent #41 starting.\n",
      "Agent #48 finished with score 0.0\n",
      "Agent #41 finished with score 168.0\n",
      "Waiting for env...\n",
      "1\n",
      "Waiting for env...\n",
      "1\n",
      "Agent #37 starting.\n",
      "Agent #44 starting.\n",
      "Agent #37 finished with score 0.0\n",
      "Agent #44 finished with score 0.0\n",
      "Waiting for env...\n",
      "1\n",
      "Agent #47 starting.\n",
      "Agent #47 finished with score 0.0\n",
      "Waiting for env...\n",
      "1\n",
      "Agent #40 starting.\n",
      "Agent #40 finished with score 0.0\n",
      "Waiting for env...\n",
      "1\n",
      "Agent #36 starting.\n",
      "Waiting for env...\n",
      "1\n",
      "Agent #43 starting.\n",
      "Agent #36 finished with score 0.0\n",
      "Agent #43 finished with score 0.0\n",
      "Waiting for env...\n",
      "1\n",
      "Agent #46 starting.\n",
      "Agent #46 finished with score 0.0\n",
      "Waiting for env...\n",
      "1\n",
      "Agent #39 starting.\n",
      "Agent #39 finished with score 0.0\n",
      "Waiting for env...\n",
      "1\n",
      "Agent #42 starting.\n",
      "Waiting for env...\n",
      "1\n",
      "Agent #35 starting.\n",
      "Agent #42 finished with score 0.0\n",
      "Agent #35 finished with score 0.0\n",
      "Waiting for env...\n",
      "2\n",
      "Agent #38 starting.\n",
      "Waiting for env...\n",
      "1\n",
      "Agent #33 starting.\n",
      "Agent #38 finished with score 0.0\n",
      "Agent #33 finished with score 0.0\n",
      "Waiting for env...\n",
      "1\n",
      "Agent #34 starting.\n",
      "Agent #34 finished with score 0.0\n",
      "Waiting for env...\n",
      "1\n",
      "Agent #29 starting.\n",
      "Agent #29 finished with score 0.0\n",
      "Waiting for env...\n",
      "2\n",
      "Agent #32 starting.\n",
      "Agent #32 finished with score 0.0\n",
      "Waiting for env...\n",
      "2\n",
      "Agent #25 starting.\n",
      "Agent #25 finished with score 0.0\n",
      "Waiting for env...\n",
      "2\n",
      "Agent #28 starting.\n",
      "Waiting for env...\n",
      "1\n",
      "Agent #21 starting.\n",
      "Agent #28 finished with score 0.0\n",
      "Agent #21 finished with score 0.0\n",
      "Waiting for env...\n",
      "1\n",
      "Agent #31 starting.\n",
      "Agent #31 finished with score 0.0\n",
      "Waiting for env...\n",
      "1\n",
      "Agent #24 starting.\n",
      "Agent #24 finished with score 0.0\n",
      "Waiting for env...\n",
      "1\n",
      "Agent #27 starting.\n",
      "Waiting for env...\n",
      "1\n",
      "Agent #20 starting.\n",
      "Agent #27 finished with score 147.0\n",
      "Waiting for env...\n",
      "1\n",
      "Agent #30 starting.\n",
      "Agent #20 finished with score 0.0\n",
      "Agent #30 finished with score 0.0\n",
      "Waiting for env...\n",
      "1\n",
      "Agent #23 starting.\n",
      "Agent #23 finished with score 0.0\n",
      "Waiting for env...\n",
      "Waiting for env...\n",
      "2\n",
      "2\n",
      "Agent #19 starting.\n",
      "Agent #26 starting.\n",
      "Waiting for env...\n",
      "2\n",
      "Agent #22 starting.\n",
      "Agent #26 finished with score 0.0\n",
      "Agent #19 finished with score 0.0\n",
      "Agent #22 finished with score 126.0\n",
      "Waiting for env...\n",
      "1\n",
      "Agent #17 starting.\n",
      "Agent #17 finished with score 0.0\n",
      "Waiting for env...\n",
      "2\n",
      "Agent #18 starting.\n",
      "Waiting for env...\n",
      "1\n",
      "Agent #13 starting.\n",
      "Agent #18 finished with score 0.0\n",
      "Waiting for env...\n",
      "2\n",
      "Agent #16 starting.\n",
      "Agent #13 finished with score 0.0\n",
      "Agent #16 finished with score 0.0\n",
      "Waiting for env...\n",
      "1\n",
      "Agent #9 starting.\n",
      "Agent #9 finished with score 105.0\n",
      "Waiting for env...\n",
      "1\n",
      "Agent #5 starting.\n",
      "Waiting for env...\n",
      "1\n",
      "Agent #12 starting.\n",
      "Waiting for env...\n",
      "1\n",
      "Agent #15 starting.\n",
      "Agent #5 finished with score 0.0\n",
      "Agent #12 finished with score 0.0\n",
      "Waiting for env...\n",
      "1\n",
      "Agent #15 finished with score 0.0\n",
      "Agent #8 starting.\n",
      "Agent #8 finished with score 0.0\n",
      "Waiting for env...\n",
      "1\n",
      "Agent #11 starting.\n",
      "Waiting for env...\n",
      "1\n",
      "Agent #4 starting.\n",
      "Waiting for env...\n",
      "1\n",
      "Waiting for env...\n",
      "1\n",
      "Agent #14 starting.\n",
      "Agent #7 starting.\n",
      "Agent #11 finished with score 0.0\n",
      "Agent #4 finished with score 0.0\n",
      "Agent #7 finished with score 0.0\n",
      "Agent #14 finished with score 0.0\n",
      "Waiting for env...\n",
      "1\n",
      "Agent #6 starting.\n",
      "Waiting for env...\n",
      "1\n",
      "Waiting for env...\n",
      "1\n",
      "Agent #3 starting.\n",
      "Agent #10 starting.\n",
      "Agent #6 finished with score 0.0\n",
      "Agent #3 finished with score 0.0\n",
      "Agent #10 finished with score 0.0\n",
      "Waiting for env...\n",
      "1\n",
      "Agent #1 starting.\n",
      "Agent #1 finished with score 168.0\n",
      "Waiting for env...\n",
      "3\n",
      "Agent #2 starting.\n",
      "Waiting for env...\n",
      "3\n",
      "Agent #0 starting.\n",
      "Agent #2 finished with score 0.0\n",
      "Agent #0 finished with score 105.0\n",
      "Time Taken (Running agents): 220.163089991\n",
      "Time Taken (Getting scores): 0.00269603729248\n",
      "{'DefTaskName': 168.0}\n",
      "{'DefTaskName': 189.0}\n",
      "{'DefTaskName': 0.0}\n",
      "{'DefTaskName': 168.0}\n",
      "{'DefTaskName': 0.0}\n",
      "{'DefTaskName': 0.0}\n",
      "{'DefTaskName': 0.0}\n",
      "{'DefTaskName': 0.0}\n",
      "{'DefTaskName': 0.0}\n",
      "{'DefTaskName': 0.0}\n",
      "{'DefTaskName': 0.0}\n",
      "{'DefTaskName': 0.0}\n",
      "{'DefTaskName': 0.0}\n",
      "{'DefTaskName': 0.0}\n",
      "{'DefTaskName': 0.0}\n",
      "{'DefTaskName': 0.0}\n",
      "{'DefTaskName': 0.0}\n",
      "{'DefTaskName': 0.0}\n",
      "{'DefTaskName': 0.0}\n",
      "{'DefTaskName': 0.0}\n",
      "{'DefTaskName': 0.0}\n",
      "{'DefTaskName': 0.0}\n",
      "{'DefTaskName': 0.0}\n",
      "{'DefTaskName': 0.0}\n",
      "{'DefTaskName': 147.0}\n",
      "{'DefTaskName': 0.0}\n",
      "{'DefTaskName': 0.0}\n",
      "{'DefTaskName': 0.0}\n",
      "{'DefTaskName': 0.0}\n",
      "{'DefTaskName': 0.0}\n",
      "{'DefTaskName': 126.0}\n",
      "{'DefTaskName': 0.0}\n",
      "{'DefTaskName': 0.0}\n",
      "{'DefTaskName': 0.0}\n",
      "{'DefTaskName': 0.0}\n",
      "{'DefTaskName': 105.0}\n",
      "{'DefTaskName': 0.0}\n",
      "{'DefTaskName': 0.0}\n",
      "{'DefTaskName': 0.0}\n",
      "{'DefTaskName': 0.0}\n",
      "{'DefTaskName': 0.0}\n",
      "{'DefTaskName': 0.0}\n",
      "{'DefTaskName': 0.0}\n",
      "{'DefTaskName': 0.0}\n",
      "{'DefTaskName': 0.0}\n",
      "{'DefTaskName': 0.0}\n",
      "{'DefTaskName': 0.0}\n",
      "{'DefTaskName': 168.0}\n",
      "{'DefTaskName': 0.0}\n",
      "{'DefTaskName': 105.0}\n",
      "Time Taken (Getting agents): 200.71570611\n",
      "Time Taken (Applying Scores): 0.000431060791016\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 12] Cannot allocate memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-984412e943f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# run generation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mtStart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# skipTasks=[] so we get all agents, even if already scored,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ryan/anaconda3/envs/oaigym/lib/python2.7/multiprocessing/__init__.pyc\u001b[0m in \u001b[0;36mPool\u001b[0;34m(processes, initializer, initargs, maxtasksperchild)\u001b[0m\n\u001b[1;32m    230\u001b[0m     '''\n\u001b[1;32m    231\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxtasksperchild\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mRawValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtypecode_or_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ryan/anaconda3/envs/oaigym/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, processes, initializer, initargs, maxtasksperchild)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_processes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocesses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repopulate_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         self._worker_handler = threading.Thread(\n",
      "\u001b[0;32m/home/ryan/anaconda3/envs/oaigym/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36m_repopulate_pool\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Process'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PoolWorker'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdaemon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m             \u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'added worker'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ryan/anaconda3/envs/oaigym/lib/python2.7/multiprocessing/process.pyc\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mforking\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;31m# reference to the process object (see bpo-30775)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ryan/anaconda3/envs/oaigym/lib/python2.7/multiprocessing/forking.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m'random'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 12] Cannot allocate memory"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process PoolWorker-2:\n",
      "Process PoolWorker-3:\n",
      "Process PoolWorker-4:\n",
      "Process PoolWorker-5:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ryan/anaconda3/envs/oaigym/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"/home/ryan/anaconda3/envs/oaigym/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"/home/ryan/anaconda3/envs/oaigym/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"/home/ryan/anaconda3/envs/oaigym/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "    self.run()\n",
      "    self.run()\n",
      "  File \"/home/ryan/anaconda3/envs/oaigym/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self.run()\n",
      "  File \"/home/ryan/anaconda3/envs/oaigym/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self.run()\n",
      "  File \"/home/ryan/anaconda3/envs/oaigym/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "  File \"/home/ryan/anaconda3/envs/oaigym/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "  File \"/home/ryan/anaconda3/envs/oaigym/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/home/ryan/anaconda3/envs/oaigym/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ryan/anaconda3/envs/oaigym/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "  File \"/home/ryan/anaconda3/envs/oaigym/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "    task = get()\n",
      "    task = get()\n",
      "    task = get()\n",
      "    task = get()\n",
      "  File \"/home/ryan/anaconda3/envs/oaigym/lib/python2.7/multiprocessing/queues.py\", line 374, in get\n",
      "  File \"/home/ryan/anaconda3/envs/oaigym/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "  File \"/home/ryan/anaconda3/envs/oaigym/lib/python2.7/multiprocessing/queues.py\", line 374, in get\n",
      "    racquire()\n",
      "  File \"/home/ryan/anaconda3/envs/oaigym/lib/python2.7/multiprocessing/queues.py\", line 374, in get\n",
      "KeyboardInterrupt\n",
      "    racquire()\n",
      "    return recv()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "    racquire()\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "import time\n",
    "\n",
    "tStart = time.time()\n",
    "\n",
    "lock = mp.Lock()\n",
    "\n",
    "trainer = TpgTrainer(actions=range(7), teamPopSizeInit=50)\n",
    "\n",
    "processes = 4 # how many to run concurrently (4 is best for my local desktop)\n",
    "\n",
    "m = mp.Manager()\n",
    "envQueue = m.Queue()\n",
    "# each process needs its own environment\n",
    "for i in range(processes):\n",
    "    envQueue.put(gym.make('Assault-v0'))\n",
    "    \n",
    "summaryScores = [] # record score summaries for each gen (min, max, avg)\n",
    "    \n",
    "    \n",
    "for gen in range(5): # generation loop\n",
    "    curScores = m.Queue() # hold scores in a generation (queue so thread safe)\n",
    "    agentQueue = m.Queue() # hold agents when finish, to actually apply score\n",
    "    \n",
    "    # run generation\n",
    "    pool = mp.Pool(processes=processes)\n",
    "    tStart = time.time()\n",
    "    # skipTasks=[] so we get all agents, even if already scored,\n",
    "    # just to report the obtained score for all agents.\n",
    "    pool.map(runAgent, \n",
    "                 [(agent, envQueue, curScores, agentQueue) \n",
    "                  for agent in trainer.getAllAgents(skipTasks=[])])\n",
    "    print('Time Taken (Running agents): ' + str(time.time() - tStart)) \n",
    "        \n",
    "    tStart = time.time()\n",
    "    scores = [] # convert scores into list\n",
    "    while not curScores.empty():\n",
    "        scores.append(curScores.get())\n",
    "    print('Time Taken (Getting scores): ' + str(time.time() - tStart)) \n",
    "        \n",
    "    tStart = time.time()\n",
    "    agents = [] # convert scores into list\n",
    "    while not agentQueue.empty():\n",
    "        agents.append(agentQueue.get())\n",
    "        print(agents[-1].team.outcomes)\n",
    "    print('Time Taken (Getting agents): ' + str(time.time() - tStart)) \n",
    "    \n",
    "    # apply scores\n",
    "    tStart = time.time()\n",
    "    trainer.applyAgentsScores(agents)\n",
    "    print('Time Taken (Applying Scores): ' + str(time.time() - tStart)) \n",
    "\n",
    "    # at end of generation, make summary of scores\n",
    "    summaryScores.append((min(scores), \n",
    "                    max(scores),\n",
    "                    sum(scores)/len(scores))) # min, max, avg\n",
    "    trainer.evolve()\n",
    "    \n",
    "clear_output(wait=True)\n",
    "print('Time Taken (Seconds): ' + str(time.time() - tStart))\n",
    "print('Results: ' + str(summaryScores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Tournament Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:oaigym]",
   "language": "python",
   "name": "conda-env-oaigym-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
