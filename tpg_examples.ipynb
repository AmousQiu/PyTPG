{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPG Examples\n",
    "This document shows how to use the PyTPG API. We make use of OpenAI Gym to run examples, and we assume you already have PyTPG installed, see the readme for installation instructions for PyTPG."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "# imports to run OpenAI Gym in Jupyter\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "# how to render in Jupyter: \n",
    "# https://stackoverflow.com/questions/40195740/how-to-run-openai-gym-render-over-a-server\n",
    "# https://www.youtube.com/watch?v=O84KgRt6AJI\n",
    "def show_state(env, step=0, name='', info=''):\n",
    "    plt.figure(3)\n",
    "    plt.clf()\n",
    "    plt.imshow(env.render(mode='rgb_array'))\n",
    "    plt.title(\"%s | Step: %d %s\" % (name, step, info))\n",
    "    plt.axis('off')\n",
    "\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    \n",
    "# transforms the state into what the tpg agent can use.\n",
    "# From 3D to 1D, taking only red data (from rgb array)\n",
    "def getState(state):\n",
    "    state2 = []\n",
    "    for x in state:\n",
    "        for y in x:\n",
    "            state2.append(y[0])\n",
    "            \n",
    "    return state2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env = gym.make('Assault-v0') # make the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(7)\n"
     ]
    }
   ],
   "source": [
    "print(env.action_space) # learn size of action space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import to do training\n",
    "from tpg.tpg_trainer import TpgTrainer\n",
    "# import to run an agent (always needed)\n",
    "from tpg.tpg_agent import TpgAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generational Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import time # for tracking time\n",
    "\n",
    "tStart = time.time()\n",
    "\n",
    "# first create an instance of the TpgTrainer\n",
    "# this creates the whole population and everything\n",
    "trainer = TpgTrainer(actions=range(7), teamPopSizeInit=50)\n",
    "\n",
    "curScores = [] # hold scores in a generation\n",
    "summaryScores = [] # record score summaries for each gen (min, max, avg)\n",
    "\n",
    "# 5 generations isn't much (not even close), but some improvements\n",
    "# should be seen.\n",
    "for gen in range(5): # generation loop\n",
    "    curScores.clear() # new list per gen\n",
    "    \n",
    "    while True: # loop to go through agents\n",
    "        teamNum = trainer.remainingAgents()\n",
    "        agent = trainer.getNextAgent()\n",
    "        if agent is None:\n",
    "            break # no more agents, so proceed to next gen\n",
    "        \n",
    "        state = env.reset() # get initial state and prep environment\n",
    "        score = 0\n",
    "        for i in range(20): # run episodes that last 200 frames\n",
    "            show_state(env, i, 'Assault', 'Gen #' + str(gen) + \n",
    "                       ', Team #' + str(teamNum) +\n",
    "                       ', Score: ' + str(score)) # render env\n",
    "            \n",
    "            act = agent.act(getState(state)) # get action from agent\n",
    "            \n",
    "            # feedback from env\n",
    "            state, reward, isDone, debug = env.step(act)\n",
    "            score += reward # accumulate reward in score\n",
    "            if isDone:\n",
    "                break # end early if losing state\n",
    "                \n",
    "        agent.reward(score) # must reward agent\n",
    "        curScores.append(score) # store score\n",
    "            \n",
    "    # at end of generation, make summary of scores\n",
    "    summaryScores.append((min(curScores), max(curScores),\n",
    "                    sum(curScores)/len(curScores))) # min, max, avg\n",
    "    trainer.evolve()\n",
    "    \n",
    "print('Time Taken (Seconds): ' + str(time.time() - tStart))\n",
    "print('Results: ' + str(summaryScores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generational Selection with Multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/connection.py\", line 398, in _send_bytes\n",
      "    self._send(buf)\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/connection.py\", line 397, in _send_bytes\n",
      "    self._send(header)\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/connection.py\", line 397, in _send_bytes\n",
      "    self._send(header)\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/connection.py\", line 397, in _send_bytes\n",
      "    self._send(header)\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/connection.py\", line 397, in _send_bytes\n",
      "    self._send(header)\n",
      "  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for env...\n",
      "Waiting for env...\n",
      "Waiting for env...\n",
      "Waiting for env...\n",
      "Waiting for env...\n",
      "Waiting for env...\n",
      "Waiting for env...\n",
      "Waiting for env...\n",
      "Waiting for env...\n",
      "Waiting for env...\n",
      "Waiting for env...\n",
      "Waiting for env...\n",
      "Waiting for env...\n",
      "Waiting for env...\n",
      "Waiting for env...\n",
      "Waiting for env...\n",
      "Waiting for env...\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "handle is closed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n    return list(map(*args))\n  File \"<ipython-input-8-0045c3c40031>\", line 19, in runAgent\n    env = envQueue.get() # get an environment\n  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/queues.py\", line 94, in get\n    res = self._recv_bytes()\n  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/connection.py\", line 212, in recv_bytes\n    self._check_closed()\n  File \"/home/amaral/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/connection.py\", line 136, in _check_closed\n    raise OSError(\"handle is closed\")\nOSError: handle is closed\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-0045c3c40031>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# run generation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunAgent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetAllAgents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;31m# at end of generation, make summary of scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         '''\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/oaigym/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: handle is closed"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool, Queue\n",
    "import time\n",
    "\n",
    "trainer = TpgTrainer(actions=range(7), teamPopSizeInit=50)\n",
    "workers = 5 # amount of workers to have running parallely\n",
    "\n",
    "envQueue = Queue()\n",
    "# each worker needs its own environment\n",
    "for i in range(workers):\n",
    "    envQueue.put(gym.make('Assault-v0'))\n",
    "    \n",
    "summaryScores = [] # record score summaries for each gen (min, max, avg)\n",
    "\n",
    "# run agent in function to work with multiprocessing\n",
    "def runAgent(agent):\n",
    "    print('Waiting for env...')\n",
    "    env = envQueue.get() # get an environment\n",
    "    print('Agent #' + str(agent.getId()) + ' starting.')\n",
    "    state = env.reset() # get initial state and prep environment\n",
    "    score = 0\n",
    "    for i in range(200): # run episodes that last 200 frames\n",
    "        act = agent.act(getState(state)) # get action from agent\n",
    "\n",
    "        # feedback from env\n",
    "        state, reward, isDone, debug = env.step(act)\n",
    "        score += reward # accumulate reward in score\n",
    "        if isDone:\n",
    "            break # end early if losing state\n",
    "\n",
    "    agent.reward(score) # must reward agent\n",
    "    curScores.put(score) # store score\n",
    "    \n",
    "    print('Agent #' + str(agent.getId()) + ' finished with score ' + str(score))\n",
    "    \n",
    "    envQueue.put(env) # put environment back\n",
    "    \n",
    "    \n",
    "for gen in range(5): # generation loop\n",
    "    curScores = Queue() # hold scores in a generation (queue so thread safe)\n",
    "    \n",
    "    # run generation\n",
    "    pool = Pool(workers)\n",
    "    pool.map(runAgent, trainer.getAllAgents())\n",
    "            \n",
    "    # at end of generation, make summary of scores\n",
    "    scoreRec.append((min(list(curScores)), max(list(curScores)),\n",
    "                    sum(list(curScores))/len(curScores))) # min, max, avg\n",
    "    \n",
    "print('Time Taken (Seconds): ' + str(time.time() - tStart))\n",
    "print('Results: ' + str(scoreRec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Tournament Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:oaigym]",
   "language": "python",
   "name": "conda-env-oaigym-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
